{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cb93d19-a454-4575-aad0-55feac7d766a",
   "metadata": {},
   "source": [
    "# Turn on Llama models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ce0bcf-ce21-46ea-8d18-08ee8281e78a",
   "metadata": {},
   "source": [
    "To access Bedrock a model must be selected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f8457f-2f2f-43f1-beab-04e9d64f9b78",
   "metadata": {},
   "source": [
    "In Bedrock (in the AWS Console)\n",
    "* Select Providers\n",
    "* Scroll down and select Request model access (does not matter what provider is selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab4ec40-0932-480b-87a3-532fcf61bd9c",
   "metadata": {},
   "source": [
    "![Provider](../images/01manage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86886c0d-cb8b-4eb9-93a0-24a9facb751c",
   "metadata": {},
   "source": [
    "* In Model access select Manage model access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a46d0f5-d98f-4805-835b-ad111d583334",
   "metadata": {},
   "source": [
    "![Model](../images/02basemodels.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8ab292-5556-4f0f-82e2-88d17635ccb1",
   "metadata": {},
   "source": [
    "* Scroll down to Meta and select Llama 2 Chat 13B and Llama 2 13B (I had originally only selected Llama 2 13B, but had some problems with the playground not working, so it seems best to treat these as a pair)\n",
    "* Select Request model access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e6dbb4-66b6-46b8-8276-e175e915b1af",
   "metadata": {},
   "source": [
    "![Request](../images/03request.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa212c9-a994-442d-9c01-9b2ad9d42dbb",
   "metadata": {},
   "source": [
    "* The models now show as In Progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42abf1e7-cf0c-42b7-882d-30969c58d6cd",
   "metadata": {},
   "source": [
    "![Progress](../images/04inprogress.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af590c00-c067-45ae-8dd4-d3419401e474",
   "metadata": {},
   "source": [
    "* After a few minutes the models are available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64df7d1d-b847-474a-b4dc-c38019dfd80c",
   "metadata": {},
   "source": [
    "![Granted](../images/05accessgranted.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e672028-cc88-4202-bab4-c69c0eef0e12",
   "metadata": {},
   "source": [
    "# Access Llama Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cae5adf-c29a-4ea9-8b93-6c4e195abb46",
   "metadata": {},
   "source": [
    "The following assumes AWS can be accessed from a locally running notebook (i.e. using a token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f9ade9-e54e-4a18-a639-b2ac5817fa9d",
   "metadata": {},
   "source": [
    "Import the libraries and create an instance of the bedrock runtime (change the region_name if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72e057ea-55c3-4128-9663-76d2cb1ff0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "bedrock = boto3.client(service_name='bedrock-runtime', region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d3f4ee-a0fe-4c69-a486-89658ed562da",
   "metadata": {},
   "source": [
    "Create the parameters\n",
    "* The prompt can be changed to ask a different question\n",
    "* It seems like max_gen_len should always be supplied to prevent runaway charges\n",
    "* The modelId can be changed if a different model is selected, but the body will also need to be changed to match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "255de490-9fff-4df5-84a0-1a229f7efe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = json.dumps({\n",
    "    \"prompt\": \"What is the average lifespan of a Llama?\",\n",
    "    \"max_gen_len\": 128,\n",
    "    \"temperature\": 0.1,\n",
    "    \"top_p\": 0.9,\n",
    "})\n",
    "\n",
    "modelId = 'meta.llama2-13b-chat-v1'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4cb443-3d9e-4b80-b279-dd8b90810789",
   "metadata": {},
   "source": [
    "Invoke the model and get the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "383fb488-e61c-42f9-86b6-28b012f00ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8740c691-1d60-4d8f-9a3d-6158810e400e",
   "metadata": {},
   "source": [
    "Read and print the body from the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42842dd2-81eb-4a1a-bf58-430d8aaa955e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generation': \"\\n\\nThe average lifespan of a llama is between 15 and 25 years, with some individuals living into their 30s. Factors such as breed, living conditions, and health can affect a llama's lifespan.\",\n",
       " 'prompt_token_count': 14,\n",
       " 'generation_token_count': 57,\n",
       " 'stop_reason': 'stop'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_body = json.loads(response.get('body').read())\n",
    "response_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3b80e9-e4a3-431a-9be6-043d5d924148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
